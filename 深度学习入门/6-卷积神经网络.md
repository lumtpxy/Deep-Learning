卷积神经网络（Convolutional Neural Network，CNN）。CNN被用于图像识别、语音识别等各种场合，在图像识别的比赛中，基于深度学习的方法几乎都以CNN为基础

## 整体结构

CNN和之前介绍的神经网络一样，可以像乐高积木一样通过组装层来构建。不过，CNN中新出现了卷积层（Convolution层）和池化层（Pooling层）

之前介绍的神经网络中，相邻层的所有神经元之间都有连接，这称为**全连接**

## 卷积层

CNN中出现了一些特有的术语，比如填充、步幅等。此外，各层中传递的数据是有形状的数据

### 全连接层存在的问题

全连接层存在什么问题呢？
那就是数据的形状被”忽视“了。全连接层会忽视形状，将全部的输入数据作为相同的神经元（同一维度的神经元）处理，所以无法利用与形状相关的信息

而卷积层可以保持形状不变。当输入数据是图像时，卷积层会以3维数据的形式接收输入数据，并同样以3维数据的形式输出至下一层。
另外，CNN中，有时将卷积层的输入输出数据称为**特征图**

### 卷积运算

卷积层进行的处理就是卷积运算。

对于输入数据，卷积运算以一定间隔滑动滤波器的窗口并应用。将各个位置上滤波器的元素和输入的对应元素相乘，然后再求和。然后将这个结果保存到输出的对应位置。将这个过程在所有位置都进行一遍，就可以得到卷积运算的输出

在全连接的神经网络中，除了权重参数，还存在偏置。CNN中，滤波器的参数就对应之前的权重。并且，CNN中也存在偏置

### 填充

在进行卷积层的处理之前，有时要向输入数据的周围填入固定的数据（比如0等），这称为**填充**

> :pushpin:
> 使用填充主要是为了调整输出的大小。
> 每次进行卷积运算都会缩小空间，那么在某个时刻输出大小就有可能变为1，导致无法再应用卷积运算。为了避免出现这样的情况，就要使用填充

### 步幅

应用滤波器的位置间隔称为**步幅**

增大步幅后，输出大小会变小；而增大填充后，输出大小会变大

## 池化层

池化是缩小高、长方向上的空间的运算

**池化层的特征**

**没有要学习的参数**
池化层和卷积层不同，没有要学习的参数。池化只是从目标区域中取最大值（或者平均值），所以不存在要学习的参数

**通道数不发生变化**
经过池化运算，输入数据和输出数据的通道数不会发生变化

**对微小的位置变化具有鲁棒性（健壮）**
输入数据发生微小偏差时，池化仍会返回相同的结果

-------

## 本章所学的内容

1. CNN在此前的全连接层的网络中新增了卷积层和池化层
2. 使用im2col函数可以简单、高效地实现卷积层和池化层
3. 通过CNN的可视化，可知随着层次变深，提取的信息愈加高级
4. LeNet 和 AlexNet 是 CNN 的代表性网络
5. 在深度学习的发展中，大数据和GPU做出了很大的贡献
